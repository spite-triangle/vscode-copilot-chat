"use strict";
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/
Object.defineProperty(exports, "__esModule", { value: true });
exports.FilterReason = exports.FinishedCompletionReason = exports.ChatRole = void 0;
exports.isApiUsage = isApiUsage;
exports.getCAPITextPart = getCAPITextPart;
exports.rawMessageToCAPI = rawMessageToCAPI;
const prompt_tsx_1 = require("@vscode/prompt-tsx");
const rawTypes_1 = require("@vscode/prompt-tsx/dist/base/output/rawTypes");
const thinkingDataContainer_1 = require("../../endpoint/common/thinkingDataContainer");
function isApiUsage(obj) {
    return typeof obj.prompt_tokens === 'number' &&
        typeof obj.completion_tokens === 'number' &&
        typeof obj.total_tokens === 'number';
}
var ChatRole;
(function (ChatRole) {
    ChatRole["System"] = "system";
    ChatRole["User"] = "user";
    ChatRole["Assistant"] = "assistant";
    ChatRole["Function"] = "function";
    ChatRole["Tool"] = "tool";
})(ChatRole || (exports.ChatRole = ChatRole = {}));
function getCAPITextPart(content) {
    if (Array.isArray(content)) {
        return content.map((part) => getCAPITextPart(part)).join('');
    }
    else if (typeof content === 'string') {
        return content;
    }
    else if (typeof content === 'object' && 'text' in content) {
        return content.text;
    }
    else {
        return '';
    }
}
function rawMessageToCAPI(message, callback) {
    if (Array.isArray(message)) {
        return message.map(m => rawMessageToCAPI(m, callback));
    }
    const out = (0, prompt_tsx_1.toMode)(prompt_tsx_1.OutputMode.OpenAI, message);
    if ('copilot_references' in message) {
        out.copilot_references = message.copilot_references;
    }
    if ('copilot_confirmations' in message) {
        out.copilot_confirmations = message.copilot_confirmations;
    }
    if (typeof out.content === 'string') {
        out.content = out.content.trimEnd();
    }
    else {
        for (const part of out.content) {
            if (part.type === 'text') {
                part.text = part.text.trimEnd();
            }
        }
    }
    if (message.content.find(part => part.type === rawTypes_1.ChatCompletionContentPartKind.CacheBreakpoint)) {
        out.copilot_cache_control = { type: 'ephemeral' };
    }
    for (const content of message.content) {
        if (content.type === prompt_tsx_1.Raw.ChatCompletionContentPartKind.Opaque) {
            const data = (0, thinkingDataContainer_1.rawPartAsThinkingData)(content);
            if (callback && data) {
                callback(out, data);
            }
        }
    }
    return out;
}
var FinishedCompletionReason;
(function (FinishedCompletionReason) {
    /**
     * Reason generated by the server. See https://platform.openai.com/docs/guides/gpt/chat-completions-api
     */
    FinishedCompletionReason["Stop"] = "stop";
    /**
     * Reason generated by the server. See https://platform.openai.com/docs/guides/gpt/chat-completions-api
     */
    FinishedCompletionReason["Length"] = "length";
    /**
     * Reason generated by the server. See https://platform.openai.com/docs/guides/gpt/chat-completions-api
     */
    FinishedCompletionReason["FunctionCall"] = "function_call";
    /**
     * Reason generated by the server. See https://platform.openai.com/docs/guides/gpt/chat-completions-api
     */
    FinishedCompletionReason["ToolCalls"] = "tool_calls";
    /**
     * Reason generated by the server. See https://platform.openai.com/docs/guides/gpt/chat-completions-api
     */
    FinishedCompletionReason["ContentFilter"] = "content_filter";
    /**
     * Reason generated by the server (CAPI). Happens when the stream cannot be completed and the server must terminate the response.
     */
    FinishedCompletionReason["ServerError"] = "error";
    /**
     * Reason generated by the client when the finish callback asked for processing to stop.
     */
    FinishedCompletionReason["ClientTrimmed"] = "client-trimmed";
    /**
     * Reason generated by the client when we never received a finish_reason for this particular completion (indicates a server-side bug)
     */
    FinishedCompletionReason["ClientIterationDone"] = "Iteration Done";
    /**
     * Reason generated by the client when we never received a finish_reason for this particular completion (indicates a server-side bug)
     */
    FinishedCompletionReason["ClientDone"] = "DONE";
})(FinishedCompletionReason || (exports.FinishedCompletionReason = FinishedCompletionReason = {}));
/**
 * Contains the possible reasons a response can be filtered
 */
var FilterReason;
(function (FilterReason) {
    /**
     * Content deemed to be hateful
     */
    FilterReason["Hate"] = "hate";
    /**
     * Content deemed to cause self harm
     */
    FilterReason["SelfHarm"] = "self_harm";
    /**
     * Content deemed to be sexual in nature
     */
    FilterReason["Sexual"] = "sexual";
    /**
     * Content deemed to be violent in nature
     */
    FilterReason["Violence"] = "violence";
    /**
     * Content contains copyrighted material
     */
    FilterReason["Copyright"] = "snippy";
    /**
     * The prompt was filtered, the reason was not provided
     */
    FilterReason["Prompt"] = "prompt";
})(FilterReason || (exports.FilterReason = FilterReason = {}));
//# sourceMappingURL=openai.js.map